{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bedrock モデルと Langchain エージェントの統合\n",
    "\n",
    "特定のアプリケーションでは、ユーザー入力に応じて、言語モデルや各種ユーティリティへの呼び出しシーケンスを調整する必要があります。LangChain エージェントインターフェイスを使用すると、アプリケーションに柔軟性を持たせることができます。エージェントはさまざまなリソースを利用でき、ユーザーの入力に基づいて使用するリソースを選択します。エージェントは複数のツールを使用でき、あるツールの出力を別のツールの入力として使用できます。\n",
    "\n",
    "エージェントには2つの主なカテゴリがあります:\n",
    "\n",
    "- アクションエージェント:各ステップで、アクションエージェントは以前のすべてのアクションの出力を使用して後続のアクションを決定します。\n",
    "- エージェントの計画と実行:これらのエージェントは、最初にアクションの完全な順序を決定し、プランを更新せずにアクションを実行します。\n",
    "\n",
    "このノートブックでは、`Zero-shot ReAct` (これはアクションベースのエージェントで、ツールの説明のみに基づいて適切なツールを選択するために [`ReAct`](https://arxiv.org/pdf/2205.00445.pdf) フレームワークを使用します) とともに `plan-and-execute` エージェントの使用方法を確認します。そこでは、各ツールの説明を提供する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アーキテクチャ\n",
    "![](./images/arch-agents.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "\n",
    "# ---- ⚠️ AWS 環境の設定に応じて、以下の行のコメントを外して編集してください。⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "\n",
    "os.environ['SERPAPI_API_KEY'] = \"<YOUR_SERP_API_KEY>\" # https://serpapi.com/ で取得した API Key を設定してください\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_parameter = {\"temperature\": 0.0, \"top_p\": .5, \"max_tokens_to_sample\": 2000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct の使用: 言語モデルにおける推論と行動のシナジー\n",
    "\n",
    "大規模な言語モデルは、推論に対する説明とタスクに特化した応答の両方を生成することができます。\n",
    "\n",
    "推論の説明を生成することで、モデルはアクションプランを設定、監視、修正でき、予期しないシナリオにも対応できます。アクションステップにより、モデルはナレッジベースや環境などの外部ソースと通信し、情報を取得することができます。\n",
    "\n",
    "ReAct フレームワークにより、大規模な言語モデルは外部ツールとインタラクションして追加情報を得ることができ、その結果、より正確で事実に基づいた応答が可能になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import  AgentExecutor, create_react_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain_community.llms.bedrock import Bedrock\n",
    "from langchain.chains.llm_math.base import LLMMathChain\n",
    "from langchain_community.utilities.serpapi import SerpAPIWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エージェント用と計算チェーン用に、それぞれ異なるモデルパラメータを持つ 2 つの固有の LLM オブジェクトをロードします。\n",
    "計算チェーン用の固有の LLM と停止シーケンスにより、計算チェーンの実行中に Claude が冗長になるのを防ぐことができます。\n",
    "\n",
    "さらに、デフォルトの LangChain テンプレートはデフォルトでは Claude に適合していないので、デフォルトのテンプレートをClaude に合わせて調整し、新しく構築したツールをツールリストに追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "react_agent_llm = Bedrock(model_id=\"anthropic.claude-instant-v1\", model_kwargs=model_parameter)\n",
    "math_chain_llm = Bedrock(model_id=\"anthropic.claude-instant-v1\",\n",
    "                         model_kwargs={\"temperature\":0,\"stop_sequences\" : [\"```output\"]})\n",
    "\n",
    "tools = load_tools([\"serpapi\"], llm=react_agent_llm)\n",
    "\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=math_chain_llm, verbose=True)\n",
    "\n",
    "llm_math_chain.llm_chain.prompt.template = \"\"\"Human: Given a question with a math problem, provide only a single line mathematical expression that solves the problem in the following format. Don't solve the expression only create a parsable expression.\n",
    "```text\n",
    "${{single line mathematical expression that solves the problem}}\n",
    "```\n",
    "\n",
    "Assistant:\n",
    " Here is an example response with a single line mathematical expression for solving a math problem:\n",
    "```text\n",
    "37593**(1/5)\n",
    "```\n",
    "\n",
    "Human: {question}\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "tools.append(\n",
    "    Tool.from_function(\n",
    "        func=llm_math_chain.run,\n",
    "        name=\"Calculator\",\n",
    "        description=\"Useful for when you need to answer questions about math.\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "{tools}\n",
    "Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do, Also try to follow steps mentioned above\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Assistant:\n",
    "{agent_scratchpad}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "                            react_agent_llm, \n",
    "                            tools, \n",
    "                            prompt=prompt_template\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"What is Amazon SageMaker? What is the launch year multiplied by 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "executor.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ツールコードの生成\n",
    "生成 AI を使用してツールのコードを作成できますか? はい、できます!   \n",
    "ただし、コードにはある程度のバリエーションがあり、人間によるレビューなしに実行するのは安全ではない場合があるので注意が必要です。\n",
    "\n",
    "次の例では、Claude によって生成されたコードを使用してツールを生成しています。EC2 インスタンスの検索ツールを boto3 python コードで実装しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "boto3_bedrock = boto3.client(service_name='bedrock-runtime',\n",
    "                             region_name=os.environ[\"AWS_DEFAULT_REGION\"])\n",
    "\n",
    "prompt_data = \"\"\"\n",
    "Human: You are an AI python code generator. You write really great code.\n",
    "\n",
    "Write a python function named list_tagged_instances with one parameter named tagname. \n",
    "\n",
    "The function queries the boto3 library to return a list all of the EC2 instances that have a tag key equal to the tagname parameter. \n",
    "\n",
    "return the code inside <code></code>\n",
    "Assistant:\"\"\"\n",
    "\n",
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 500})\n",
    "modelId = \"anthropic.claude-instant-v1\"  \n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "tree = ET.ElementTree(ET.fromstring(response_body.get(\"completion\")))\n",
    "python_code = tree.getroot().text\n",
    "\n",
    "display(Markdown(f'```{python_code}```'))\n",
    "\n",
    "exec(python_code)\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=list_tagged_instances,\n",
    "        name=\"List\",\n",
    "        description=\"List all of the EC2 instances that have a tag equal to the tagname parameter.\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## コードを実行する\n",
    "\n",
    "上記のコードが適切だと思われる場合、エージェントのツールとして使用します。\n",
    "\n",
    "**注:** コードを機能させるには、このアカウントに 'delete' という名前のタグとそのタグに任意の値を持つ EC2 インスタンスが必要です。大文字と小文字が区別されるため、これを実行する前に、EC2インスタンスを作成し、タグを設定してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = Bedrock(model_id=\"anthropic.claude-instant-v1\", client=boto3_bedrock, model_kwargs=model_parameter)\n",
    "\n",
    "agent = create_react_agent(react_agent_llm, tools, prompt=prompt_template)\n",
    "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "question = \"\"\"Please list my EC2 instances with the tag delete.\"\"\"\n",
    "\n",
    "result = executor.invoke({\"input\": question})\n",
    "\n",
    "print(f\"{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 別のシナリオ - 存在しないインスタンスを検索する\n",
    "存在しないタグを指定し、 EC2 インスタンスが見つからないことを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"\"\"Please list my EC2 instances with the tag doesnotexist.\"\"\"\n",
    "\n",
    "result = executor.invoke({\"input\": question})\n",
    "\n",
    "print(f\"{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Tool\n",
    "エージェントの一般的な用途は、データベース内のレコードを検索することです。コンテキストに完全なデータベースを含めるのは現実的ではないので、会話型のインタラクションを維持しながら、データベースに対するアクションを実行して幻覚 (ハルシネーション) を排除するツールを提供できます。\n",
    "\n",
    "### SQL データベースエージェント\n",
    "LangaChain には、DB に質問して答えを得る方法をデモするための SQL データベースエージェントがあります。詳細は、このドキュメントを参照してください: https://python.langchain.com/docs/integrations/toolkits/sql_database\n",
    "\n",
    "エージェントは DB のスキーマをコンテキストにロードし、自然言語の質問に基づいて SQL ステートメントを生成します。その後、SQL ステートメントがデータベースに対して実行され、結果が返されます。\n",
    "\n",
    "### Data エージェント\n",
    "SQL データベースエージェントは、データ探索やクエリ生成に役立ちます。また、次のステップのコンテキストをプロンプトで提供するために、データベースからデータをプルするツールを作成したい場合もあります。\n",
    "次の例では、customer テーブル内の顧客の DB クエリをシミュレートします。このコードを DynamoDB またはリレーショナルデータベースの検索に置き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_table=[\n",
    "  {\n",
    "    \"id\": 1, \n",
    "    \"first_name\": \"John\", \n",
    "    \"last_name\": \"Doe\",\n",
    "    \"age\": 35,\n",
    "    \"postal_code\": \"90210\"\n",
    "  },\n",
    "  {  \n",
    "    \"id\": 2,\n",
    "    \"first_name\": \"Jane\",\n",
    "    \"last_name\": \"Smith\", \n",
    "    \"age\": 27,\n",
    "    \"postal_code\": \"12345\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 3, \n",
    "    \"first_name\": \"Bob\",\n",
    "    \"last_name\": \"Jones\",\n",
    "    \"age\": 42,\n",
    "    \"postal_code\": \"55555\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 4,\n",
    "    \"first_name\": \"Sara\", \n",
    "    \"last_name\": \"Miller\",\n",
    "    \"age\": 29, \n",
    "    \"postal_code\": \"13579\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 5,\n",
    "    \"first_name\": \"Mark\",\n",
    "    \"last_name\": \"Davis\",\n",
    "    \"age\": 31,\n",
    "    \"postal_code\": \"02468\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 6,\n",
    "    \"first_name\": \"Laura\",\n",
    "    \"last_name\": \"Wilson\",\n",
    "    \"age\": 24,\n",
    "    \"postal_code\": \"98765\" \n",
    "  },\n",
    "  {\n",
    "    \"id\": 7,\n",
    "    \"first_name\": \"Steve\",\n",
    "    \"last_name\": \"Moore\",\n",
    "    \"age\": 36,\n",
    "    \"postal_code\": \"11223\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 8,\n",
    "    \"first_name\": \"Michelle\",\n",
    "    \"last_name\": \"Chen\",\n",
    "    \"age\": 22,\n",
    "    \"orders\": [\n",
    "        {\n",
    "            \"order_id\": 1,\n",
    "            \"description\": \"An order of 1 dozen pencils\"\n",
    "        },\n",
    "        {\n",
    "            \"order_id\": 2,\n",
    "            \"description\": \"An order of 2 markers\"\n",
    "        }\n",
    "    ],\n",
    "    \"postal_code\": \"33215\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 9,\n",
    "    \"first_name\": \"David\",\n",
    "    \"last_name\": \"Lee\",\n",
    "    \"age\": 29,\n",
    "    \"postal_code\": \"99567\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 10,\n",
    "    \"first_name\": \"Jessica\",\n",
    "    \"last_name\": \"Brown\",\n",
    "    \"age\": 18, \n",
    "    \"postal_code\": \"43210\"\n",
    "  }\n",
    "]\n",
    "\n",
    "def customer_lookup(id):\n",
    "    print(f\"search by customer {id}\")\n",
    "    for customer in customer_table:\n",
    "        if customer[\"id\"] == int(id):\n",
    "            print(f\"found customer {id} {customer}\")\n",
    "            return customer\n",
    "        \n",
    "    return None\n",
    "\n",
    "tools.append(Tool.from_function(\n",
    "        name=\"CustomerLookup\",\n",
    "        func=customer_lookup,  # Mock Function, replace with an api call\n",
    "        description=\"Use this when you need to lookup a customer by id.\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "react_agent = create_react_agent(llm, tools, prompt_template)\n",
    "executor = AgentExecutor(agent=react_agent, tools=tools, verbose=True)\n",
    "\n",
    "question = \"\"\"write one sentence summary about the information you know about the customer with an id of 2.\"\"\"\n",
    "\n",
    "result = executor.invoke({\"input\": question})\n",
    "\n",
    "print(f\"{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "00878cbed564b904a98b4a19808853cb6b9988746b881ea025a8408713879bf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
